{%- from "ceph/map.jinja" import global_settings with context -%}
{%- from "ceph/map.jinja" import mon_settings with context -%}
{%- from "ceph/map.jinja" import osd_settings with context -%}
{%- from "ceph/map.jinja" import client_settings with context -%}
{%- from "ceph/map.jinja" import rgw_settings with context -%}

[global]
    fsid = {{ global_settings.get('fsid') }}
    public network = {{ global_settings.get('public_network') }}
    cluster network = {{ global_settings.get('cluster_network') }}
    auth cluster required = cephx
    auth service required = cephx
    auth client required = cephx

{%- for mon, ip_map in salt['mine.get']('ceph:mon:enabled:true','ip_map','pillar').items() -%}
{% set tmp, mon_hostname = salt['mine.get'](mon, 'hostname').items()[0] %}
[mon.{{ mon_hostname }}]
    host = {{ mon_hostname }}
    mon addr = {{ ip_map[mon_settings.interface][0] }}:6789

{%- endfor %}

{% if osd_settings.get('enabled', False) %}
[osd]
    osd journal size = {{ salt['pillar.get']('ceph:osd:journal_size') }}
    osd pool default size = {{ salt['pillar.get']('ceph:osd:pool_default_size') }}
    osd pool default min size = {{ salt['pillar.get']('ceph:osd:pool_default_min_size') }}
    osd pool default pg num = {{ salt['pillar.get']('ceph:osd:pool_default_pg_num') }}
    osd pool default pgp num = {{ salt['pillar.get']('ceph:osd:pool_default_pgp_num') }}
    osd crush chooseleaf type = {{ salt['pillar.get']('ceph:osd:crush_chooseleaf_type') }}
    osd crush update on start = {{ salt['pillar.get']('ceph:osd:crush_update_on_start') }}
    filestore merge threshold = {{ salt['pillar.get']('ceph:osd:filestore_merge_threshold') }}
    filestore split multiple = {{ salt['pillar.get']('ceph:osd:filestore_split_multiple') }}
    filestore op threads = {{ salt['pillar.get']('ceph:osd:filestore_op_threads') }}
    filestore max sync interval = {{ salt['pillar.get']('ceph:osd:filestore_max_sync_interval') }}
    filestore min sync interval = {{ salt['pillar.get']('ceph:osd:filestore_min_sync_interval') }}
    filestore queue max ops = {{ salt['pillar.get']('ceph:osd:filestore_queue_max_ops') }}
    filestore queue max bytes = {{ salt['pillar.get']('ceph:osd:filestore_queue_max_bytes') }}
    filestore queue committing max ops = {{ salt['pillar.get']('ceph:osd:filestore_queue_committing_max_ops') }}
    filestore queue committing max bytes = {{ salt['pillar.get']('ceph:osd:filestore_queue_committing_max_bytes') }}
    osd op threads = {{ salt['pillar.get']('ceph:osd:op_threads') }}
    osd disk threads = {{ salt['pillar.get']('ceph:osd:disk_threads') }}
    osd max backfills = {{ salt['pillar.get']('ceph:osd:max_backfills') }}
    osd map cache size = {{ salt['pillar.get']('ceph:osd:map_cache_size') }}
    osd scrub load threshold = {{ salt['pillar.get']('ceph:osd:scrub_load_threshold') }}
{%- endif %}

{% if client_settings.get('enabled', False) %}
[client]
    rbd cache = {{ salt['pillar.get']('ceph:client:rbd_cache') }}
    rbd cache writethrough until flush = {{ salt['pillar.get']('ceph:client:rbd_cache_writethrough_until_flush') }}
    rbd cache size = {{ salt['pillar.get']('ceph:client:rbd_cache_size') }}
{%- endif %}

{% if rgw_settings.get('enabled', False) %}
{% for rgw, ip_map in salt['mine.get']('ceph:rgw:enabled:true','ip_map','pillar').items() -%}
{% set tmp, rgw_hostname = salt['mine.get'](rgw, 'hostname').items()[0] %}

[client.radosgw.gateway]
    host = {{ rgw_hostname }}
    rgw dns name = {{ rgw_hostname }}
    keyring = {{ rgw_settings.radosgw_keyring }}
    rgw frontends = "civetweb port=80"
    log file = /var/log/radosgw/client.radosgw.gateway.log

{% endfor -%}
{% endif %}

